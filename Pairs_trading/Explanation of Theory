Explaination behind this model:

Engele-Granger cointegration test is used in the ver first function: check_cointegration()
  checks if the spread between two stocks keeps returning to a fixed mean (they're cointegrated) or not.
  it produces a p-value to indicate if this level of cointigration is statistically significant or not.
  shocking example was GOOG and GOOGL which had p-value 0.0116
  ideally we only trade stocks with p-value <0.05
  note the test stat ("score" in the code): more negative ==> more cointegrated.

Linear regression used in the second function: calculate_hedge_ratio()
  using the simple formula: ticker2 = Î± + Î² (ticker1) + Îµ
  note: Î² = hedge ratio (ie how many shares of ticker2 offset 1 share of ticker1)
  Î± = the intercept, Îµ = the residule
  interesting example: GOOG (2) vs GOOGL (1) had Î² = 1.0048 (so for every 1 share of GOOGL we need 1.0048 shares of GOOG to be hedged -     pretty much 1:1).
  also had r-squared of 0.9994 - ie 99.94% of GOOG's movement is explained by GOOGL.

calculatin the spread between the two stocks: calculate_spread()
   note we must scale the 2nd stock by the hedge ratio, as we cannot simply subtract the price of the two stocks. so rather than the dollar difference in their prices, we look at 
   the difference in their prices relative to eachother. 
   the spread is the pricing error or mispricing between the two stocks.

creating the z-score: calculate_zscore()
  note the rolling() creates a rolling wondow meaning its like a fixed-size window that moves over the dataset, and then we take mean()'s over each window. 
  also .std() takes the standard deviation/ volitility over each of these windows. 
  note: with the stocks having a z-score we can now compare this pair to other pairs of stocks, using the same metric (zscore). also if markets change in volitility, then the 
  rolling std will adjust. 

creating the signals: generate_signals()
  we use pandas series (pd.series() ) to create two empty 1D arrays (columns) to store the positions we take each day. using the index as the same 
  index as the zscore uses (just the dates). we prefill all the data with 0's so we can iterate over it later with either +1 (long), -1 (short) 
  or remain at 0 (flat). 
  To enter a trade, the zscore entry threshold is set at 2, and exit at 0 (this can be changed). 
   note: "long spread" means we're betting the spread will increase back to normal/ the mean. and "short spread" means we think the spread will
   shrink back to the mean. 

backtesting: backtest()
  when calculating the strategy returns we first shift over all elements in the position1 and position2 series by 1, so that yesterdays' position
  will determine todays' returns. 
  effectivly: today's return = (yesterday's position in stock1 Ã— today's return of stock1) + (yesterday's position in stock2 Ã— today's return of stock2). 
  (note position = 1 or -1 or 0). 
 
  in creating the cumulative returns variable, we must add the +1 to each strategy returns so when multiplying the sequence of strategy returns
  it does not become megative, nor multiplied incorrectyl. (eg a 5% return followed by a 2% return should be 1.05x10.2 = 1.071, not 0.05x0.02 = 0.01). 
  the cumulative returns gives us the equity curve (plotted) - ie showing how $1 invested with this model would have grown. 
  note on calculating the total retun over multiple periods: using the formula: (1 + râ‚) Ã— (1 + râ‚‚) Ã— ... Ã— (1 + râ‚™) - 1 where we minus 1 at the end
  to convert the growth multiplier back into a return percentage. (eg: the final figure of the growth multiplier is 1.08, meaning for $1 you started with
  you now have $1.08, and so as a total return percentage, this is 1.08 - 1 = 0.08 or 8% growth). 

  the sharpe ratio measures the risk adjested return. we use the standard deviation of the strategy_return variable as the measurement of risk/volitility. 
  so in combination we get mean divided by std which gives us the unit: how much return per unit of risk. 
  then we use sqt(252) which comes from ðœŽ^2 = N where N = number of trading days in a year, and ðœŽ^2 = daily variances, then rearange for ðœŽ = sqt(252). 
  note ðœŽ (unsquared) represents standard deviation. 
  note: sharpe S >2 = excellent ,<2 S >1.5 = good, <1.5 S >1 = ok, S <1 = not worth it. 

  when looking at the number of trades and number of days holding a position output, be mindful of the number of years of historical date you are using. 

simplifying the meaning of the graphs:
  1st: do the stocks move together?
  2nd: when did this algorithm exicute trades? - shows short and long positions
  3rd: does the spread oscilate around the mean?
  4th: over time, did we make a profit?
  5th: how risky was it - less red = lower risk. 

note on interpreting the extra statistics att he end:
  average ratio - eg GOOGL/GOOG had 0.9946 - meaning GOOGL traded at about 99.46% of GOOG's price on average.
  the standard deviation (volatility) of the ratio - eg GOOGL/GOOG had 0.0033, meaning the ratio barley moves (good for pairs trading). 
  max drawdown - eg GOOGL/GOOG  was -3.2 ==> we never lost more than 3.2% of our capital.
  


Notes for improvement:
- better data cleaning process 
- better graphs - flexible sizing - remove the stickiness
